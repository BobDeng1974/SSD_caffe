### 7.1 工作任务

1. 模型对比
2. ssd 二次分类 roi pooling 总结
3. ssd 测试层 ReclsDetOut 总结
4. 跑一下 二次分类网络
5. 可视化测试网络
6. rcnn 论文
7. 写一个层 
8. blob 层 , 
9. data 数据层,

-----

## reclsK-X 模型对比

recls_K-X_convf_dropout_rpnalike

recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3  

recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5

recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5nmsconf0.5

recls_K-X_featuremap2_dropout_rpnalike_negratio3

recls_K-X_featuremap3_rpnalikeposebeforenmsbatch4_negratio3_iou0.5

	22236.10452.rfcn_test	(2018年06月22日 21时56分27秒)	(Detached)recls_K-X_convf_dropout_rpnalikeposebeforenmsbatch4_negratio3_iou0.5	
	21961.recls_K-X_featuremap3_rpnalikeposebeforenmsbatch4_negratio3_iou0.5	
	21840.recls_K-X_featuremap2_rpnalikeposebeforenmsbatch4_negratio3_iou0.5	
	21711.recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.6	
	3727.recls_K-X_convf_rpnalikeposebeforenms_negratio3	
	373.recls_K-X_convf_rpnalike_negratio3	
-----

```
recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5

recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5nmsconf0.5
作比较
```

|                               | s_recls | abs           |                         |
| ----------------------------- | ------- | ------------- | ----------------------- |
| negratio3_posiou0.5           |         | 高 e-4 e-5    |                         |
| negratio3_posiou0.5nmsconf0.5 | r       | 低e-4 e-5状态 | 人误分类会低一点 低0.01 |

```
recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5
recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3
```

|                     | s_recls | abs        |                         |
| ------------------- | ------- | ---------- | ----------------------- |
| negratio3_posiou0.5 |         | 高 e-4 e-5 |                         |
| negratio3           | r       | 低0.1      | 人误分类会低一点 低0.01 |

综上感觉 negratio3 最好 , 不对posiou 进行处理, 经常调整的参数有 

| feature map | negrat iou | pos iou | nms conf |
| ----------- | ---------- | ------- | -------- |
|             |            |         |          |

1. feature map 管控着二次分类从哪种尺度上面提取信息, fmp 越小 他的特征表层, 像hog一样 仅仅是可以
2. negrat iou 负样本iou 越大, 样本更容易变成负样本

-----



### 7-3 

1. ~~模型对比~~
2. ssd 二次分类 roi pooling 总结
3. ssd 测试层 ReclsDetOut 总结
4. ~~跑一下 二次分类网络~~
5. ~~可视化测试网络~~
6. rcnn 论文
7. 写一个层 
8. blob 层 , 
9. data 数据层,



总结: 

## 二次分类测试方法

![1530591589419](/tmp/1530591589419.png)

`det_proto` 是训练好了的 模型, 他只做第一次检测, `det_proto`的输出是`det_out` , 

`det_out`输出结构:  `(0, _ ,score, xmin, ymin, xmax, ymax )` , 

更改featrue map: 

	1. 修改 ![1530592069664](/tmp/1530592069664.png)

修改上图中的  `blob_name_recls` , 将`convf`变为 feature map1 or 2 or 3 
之后要更改 `recls_proto`中的维度参数

![1530592209114](/tmp/1530592209114.png)如左图, 需要更改 dim 36, 64,  convf 是1/8 尺度上的数据, 如果需要1/16 尺度		  的数据就需要把`dim: 36` 改为 `dim: 18`, `dim:64`改为`dim:32`, 如果需要1/32 尺度, 就把原图片尺寸(288,512)*1/32  变成  (9, 16) 

note: 要和 `blob_name_recls`名字对应起来/

------

## 模型比较 

113

recls_K-X_convf_dropout_rpnalikeposebeforenmsbatch4_negratio3_iou0.5
recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3
recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.6
recls_K-X_featuremap2_dropout
recls_K-X_featuremap2_dropout_rpnalike
recls_K-X_featuremap2_dropout_rpnalike_negratio3
recls_K-X_featuremap2_dropout_softfocal
recls_K-X_featuremap2_rpnalikeposebeforenmsbatch4_negratio3_iou0.5
recls_K-X_featuremap3_dropout
recls_K-X_featuremap3_rpnalikeposebeforenmsbatch4_negratio3_iou0.5



106 

recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5
recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5nmsconf0.5
recls_K-X_featuremap3_rpnalike_negratio3



所有新训练网络对一次分类分数都不会降低很多 e-5, e-4 

neg io 3 原始网络: 

| 最差误检 | 最差分数降低 |            |      |
| -------- | ------------ | ---------- | ---- |
| 0.71     | 0.008        | 大图       |      |
| 0.056    |              | 小图效果好 |      |
|          |              |            |      |



convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.6

| 最差误检 | 最差分数降低 |        |      |
| -------- | ------------ | ------ | ---- |
| 0.81     | 0.01         | 大图   |      |
| 0.22     |              | 小图差 |      |
|          |              |        |      |



加 nms conf 的 大物体 人体误检 0.8 但是比不加少0.01~0.02,  小物体不如 没加conf,  少0.02



---

### 7-4

1. ~~ssd 二次分类 roi pooling 总结~~
2. ssd 测试层 ReclsDetOut 总结
3. rcnn 论文
4. 写一个层 
5. blob 层 , 
6. data 数据层,

测试心得 : feature map 决定对大物体 还是小物体检测的准确性,
如果使用pos iou 越大得到的人误检越好, 

如何调 `nms`参数



### roi pooling 层

``` c++
layer {
  name: "roi_pooling3"
  type: "ROIPooling"
  bottom: "convf"
  bottom: "rpn_rois"
  top: "roi_pooling3"
  roi_pooling_param {
    pooled_w: 5
    pooled_h: 5
    spatial_scale: 0.125 # 1/8
  }
}
```



## 插值算法

<https://blog.csdn.net/a664607530/article/details/79314019>

cv2.resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) → dst

```
cv2.resize(src,dsize,dst=None,fx=None,fy=None,interpolation=None)

scr:原图

dsize：输出图像尺寸

fx:沿水平轴的比例因子

fy:沿垂直轴的比例因子

interpolation：插值方法

```



#### 最近邻插值

src_x = det_x * (src_w/det_w )

#### 双线性插值

src_x = det_x * (src_w/det_w )
f(i+u, j+v) = (1-u)(1-v)f(i,j) + (1-u)vf(i,j+1) + u(1-v)f(i+1,j) + uvf(i+1,j+1)

```python
# coding=utf-8
import cv2

# INTER_NEAREST  |  最近邻插值
# INTER_LINEAR   |  双线性插值（默认设置）
# INTER_AREA     |  使用像素区域关系进行重采样
# INTER_CUBIC    |  4x4像素邻域的双三次插值
# INTER_LANCZOS4 |  8x8像素邻域的Lanczos插值

img = cv2.imread("image/image_test.jpg")
src_h ,src_w = img.shape[:2]

# 缩小图
size = (int(src_w * 0.8), int(src_h * 0.7))
shrink_NEAREST = cv2.resize(img, size, interpolation=cv2.INTER_NEAREST)
shrink_LINEAR = cv2.resize(img, size, interpolation=cv2.INTER_LINEAR)
shrink_AREA = cv2.resize(img, size, interpolation=cv2.INTER_AREA)
shrink_CUBIC = cv2.resize(img, size, interpolation=cv2.INTER_CUBIC)
shrink_LANCZOS4 = cv2.resize(img, size, interpolation=cv2.INTER_LANCZOS4)

# 放大图像
fx = 1.2
fy = 1.1
enlarge_NEAREST = cv2.resize(img, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_NEAREST)
enlarge_LINEAR = cv2.resize(img, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_LINEAR)
enlarge_AREA = cv2.resize(img, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_AREA)
enlarge_CUBIC = cv2.resize(img, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_CUBIC)
enlarge_LANCZOS4 = cv2.resize(img, (0, 0), fx=fx, fy=fy, interpolation=cv2.INTER_LANCZOS4)

cv2.imwrite("shrink_NEAREST.jpg", shrink_NEAREST)
cv2.imwrite("shrink_LINEAR.jpg", shrink_LINEAR)
cv2.imwrite("shrink_AREA.jpg", shrink_AREA)
cv2.imwrite("shrink_CUBIC.jpg", shrink_CUBIC)
cv2.imwrite("shrink_LANCZOS4.jpg", shrink_LANCZOS4)

cv2.imwrite("enlarge_NEAREST.jpg", enlarge_NEAREST)
cv2.imwrite("enlarge_LINEAR.jpg", enlarge_LINEAR)
cv2.imwrite("enlarge_AREA.jpg", enlarge_AREA)
cv2.imwrite("enlarge_CUBIC.jpg", enlarge_CUBIC)
cv2.imwrite("enlarge_LANCZOS4.jpg", enlarge_LANCZOS4)
```



## Rcnn 论文

![](/home/xjx/Documents/论文/论文中图片/20151206181944105.png)

Object category classifiers

## 训练过程：

**step 1:** 对于每张图片，利用选择性搜索（SS，Selective Search）找出2K个候选区域。对每个候选区域改变其尺度和长宽比，使其与卷积神经网络要求的图片输入的规格保持一致。

**step 2**: 利用Alexnet或VGGnet初始化CNN，将最后的1000类分类器替换成21类（20类+背景）分类器，随机初始化这层权重，然后就是整个网络的fine-tuning。训练时候选区域中，与GT box（grand-true box）的IOU大于0.5标为正样本，其余为负样本。从正样本中随机抽取32个，负样本中随机抽取96个，构成一个128的min-batch。

**step 3**: 利用步骤2调整好的网络（前面的网络已经是固定了）提取特征，用SVM分类。GT box标为正，其他候选区域中与GT box的IOU小于0.3标为负，其他的舍去。

**step 4**: 边框回归

pos:  IOU大于0.5标为正样本
negs: 其余为负样本
Less clear is how to label a region that partially overlaps a car

从正样本中随机抽取32个，负样本中随机抽取96个，构成一个128的min-batch。

overlap threshold, 0.3,  Setting it to 0.5, , decreased mAP by 5 points,setting it to 0 decreased mAP by 4 points

features and training labels are applied,we optimize one linear SVM per class

use `standard hard negative mining method` , this converges quickly and  mAP stops increasing after only a single pass over all images

baselines 对照组

 four-level spatial pyramid and populates

### 3.1 Visualizing learned features 

第一次卷积网络可视化 They capture oriented edges and opponent colors

显示网络学习 可视化方法:
	The idea is to single out a particular unit (feature) in the network and use it as if it were an object detector in its own right

得到一个feature ,  把feature 当做 object detector 

The idea is to single out a particular unit (feature) in the network and use it as if it were an object detector in its own right. That is, we compute the unit’s activations on a large set of held-out region proposals (about 10 million), sort the proposals from highest to lowest activation, perform nonmaximum suppression, and then display the top-scoring regions

pool_5 局部信息,  绝大部分信息来自于之前的cnn 而不是 densely connected layers. (FC)



The boost from fine-tuning is much larger for fc 6 and fc 7 than for pool 5 ,
对fc 进行 fine-tuning 的效果比pool 层好的多,  表明 pool 从pre-training 中学到的特性是通用的, fine-tuning 改进是 在domain-specific non-linear classifiers 学到的


### 3.3 Network architectures

使用`K. Simonyan and A. Zisserman. Very Deep Convolu- tional Networks for Large-S` 网络进行特征提取



### 3.4 Detection error analysis

检测分析工具:
`Y. Jia.Caffe: An open source convolutional archi-tecture for fast feature embedding.` http://caffe.berkeleyvision.org/, 2013. 3

### 3.5 Bounding-box regression

`P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ra-manan. Object detection with discriminatively trained part based models. TPAMI, 2010 ` 收到这篇文章启发

### 4.1 Dataset overview

The ILSVRC2013 detection dataset is split into three sets: train (395,918), val (20,121), and test (40,152),

对于负样本需要动手检查, 以免出现错误, 

### 4.2 Region proposals

`J. Uijlings, K. van de Sande, T. Gevers, and A. Smeulders. Selective search for object recognition. IJCV, 2013 `

One minor modification was required to deal with the fact that selective search is not scale invariant and so the number of regions produced depends on the image resolution.

要解决的问题: ss 尺度是变化的, region 的产生依赖于图像分辨率 , 所以在ss之前把图片resize 成500 pixels 固定尺寸,



### A. Object proposal transformations 

cnn 输入需要固定尺寸 227x227 pixels.  要使用任意矩形的 proposals

#### transforming 

A、`tightest square with context`:把region proposal的边界进行扩展延伸成正方形，灰色部分用原始图片中的相应像素填补，如下图(B)所示

B.`tightest square without context`:把region proposal的边界进行扩展延伸成正方形，灰色部分不填补，如下图(C)所示;

在放缩之前，作者也考虑了，在region proposal周围补额外的原始图片像素（pad p）。两张图片第一层p=0，第二层p=16

C. `warp` 把图片直接扩展成 227x227, 直接变形 如下图(D)

![](/home/xjx/Documents/论文/论文中图片/20160315191333440.png)



骑马图的上面一行 是没有加pad 的 , 下面是引入 pad=16, 扩大了 proposal 的区域, 这样做比用图像均值进行填充效果更好.

### Positive vs. negative examples and softmax

For fine-tuning 

- we map each object proposal to the ground-truth instance with which it has maximum IoU overlap (if any) and label it as a positive for the matched ground-truth class if the IoU is at least 0.5
- All other proposals are labeled “background”
- (in fine-tuning does not emphasize precise localization)

For training SVMs ,  (pre-training)

- we take only the ground-truth boxes as positive examplesfor their respective
- classes and label proposals with less than 0.3 IoU overlap with all instances of a class as a negative for that class.
- (more than 0.3 IoU overlap, but are not ground truth) are ignored

fine-tuning 要换match 策略, 效果好.
正负样本的定义方法不是关键, 关键是fine-tuning data is limited
fine-tuning 中引入“jittered” examples (those proposals with overlap between 0.5 and 1, but not ground truth), expands the number of positive examples , 避免overfitting , 

However, we also note that using these jittered examples is likely suboptimal because the network is not being fine-tuned for precise localization.

提出了一种观点, 使用抖动的 正样本,(iou>0.5) 使用 "hard negatives"

作者讨论了为什么最后用SVM替代softmax，因为效果会提升4个点，作者认为原因在于softmax中的背景样本是共享的，而SVM的背景样本是独立的，更加hard，所以能够带来更好的分类效果。

### Bounding-box regression

关于 bounding-box regression 有两个细微的问题

1. regularization is important , we set λ = 1000 based on a validation set

2. if P is far from all ground-truth boxes, then the task of transforming P to a ground-truth box G does not make sense

   so : we only learn from a proposal P if it is nearby at least one ground-truth box,  All unassigned proposals are discarded , We do this once for each object class in order to learn a set of class-specific bounding-box regressors

---



## **论文** Selective Search for Object Recognition

 

[相关博客]: https://www.cnblogs.com/zhao441354231/p/5941190.html

使用` Selective Search(SS) `进行图像划分

![img](/home/xjx/Documents/论文/论文中图片/seletive_search.jpg)

### **第二部分: 提取每个正/负样本(都是一个个不同大小的区域)的特征**

第一部分中将正样本区域和负样本区域都提取出来了,现在就需要提取每个区域的特征了.本文主要采用了两种特征: HOG特征 + bag-of-words特征,同时辅助性地增加了SIFT,two colour SIFT,Extended OpponentSIFT,RGB-SIFT这四种特征,这样特征加起来的维度达到了惊人的360,000.

(问题2:每个区域的大小都是不相同的,如何保证提取到的每个区域的特征向量维度相同?)

### **第三部分: 分类器**

第二部分中,每个区域的特征提取出来了,真实类别标签也知道,那这就是一个2分类问题;分类器这里采用了带有Histogram Intersection Kernel的SVM分类器进行分类;这里没有对分类器本身做什么改进,我们可能会质疑一下他这种分类器的选择是否对这种场合是最好的,其他的没什么好讲的.

(问题3:选这种分类器的原因是不是它适用于处理高维度数据?)

### **第四部分: 反馈**

第三部分将分类器训练好了,训练好了就完了吗? NO! 现在流行一种反馈机制,SVM训练完成了,将得到每个训练图像每个候选区域的软分类结果(每个区域都会得到一个属于正样本的概率),一般如果概率大于0.5将被认为是目标,否则被认为是非目标,如果完全分类正确,所有的正样本的SVM输出概率都大于0.5,所有负样本的SVM输出概率都小于0.5,但是最常见的情况是有一部分的负样本的输入概率也是大于0.5的,我们会错误地将这样样本认为是目标,这些样本就称之为"False Positives".

我们这里就是想把这些"False Positives"收集起来,以刚才训练得到的SVM的权值作为其初始权值,对SVM进行二次训练,经过二次训练的SVM的分类准确度一般会有一定的提升;

**2.2 测试过程**

测试的过程基本和训练过程相同: 首先用SS方法得到测试图像上候选区域 --> 然后提取每个区域的特征向量 --> 送入已训练好的SVM进行软分类 --> 将这些区域按照概率值进行排序 --> 把概率值小于0.5的区域去除 --> 对那些概率值大于0.5的,计算每个区域与比它分数更高的区域之间的重叠程度,如果重叠程度大于30%,则把这个区域也去除了 --> 最后剩下的区域为目标区域.

(问题4:重叠程度如何计算,如果计算A与B之间的重叠程度,分子是A与B的交集,分母是A还是B?)

**总结**

**1**. 本文最大的卖点在于它的Selective Search策略,这个策略其实是借助了层次聚类的思想(可以搜索了解一下"层次聚类算法"),将层次聚类的思想应用到区域的合并上面;作者给出了SS的计算过程:

**总体思路**:假设现在图像上有n个预分割的区域,表示为R={R1, R2, ..., Rn}, 计算每个region与它相邻region(注意是相邻的区域)的相似度,这样会得到一个n*n的相似度矩阵(同一个区域之间和一个区域与不相邻区域之间的相似度可设为NaN),从矩阵中找出最大相似度值对应的两个区域,将这两个区域合二为一,这时候图像上还剩下n-1个区域; 重复上面的过程(只需要计算新的区域与它相邻区域的新相似度,其他的不用重复计算),重复一次,区域的总数目就少1,知道最后所有的区域都合并称为了同一个区域(即此过程进行了n-1次,区域总数目最后变成了1).算法的流程图如下图所示:

![img](/home/xjx/Documents/论文/论文中图片/727161-20161009103757831-1582493910.png)![img](/home/xjx/Documents/论文/论文中图片/727161-20161009103916414-1718247646.png)



# 7-5

## 任务

1. 实现caffe 层
2. 快速过一遍 opencv 
3. python 调用父类构造函数, python 迭代器
4. c++  虚函数实现机制, 
5. 数据结构题目, 
6. 卷积操作的 前向和反向 的推导,  softmax 公式的推导
7. 领域调研  经典论文 cpp iccv 顶会文章
8. 3 5 篇精度 , 补充相关 



r-cnn : https://github.com/La-fe/rcnn 

### fine-tuning

[fine-tuning]: https://www.cnblogs.com/louyihang-loves-baiyan/p/5038758.html



1. 计算数据集的均值文件, 

   ```c++
   /home/chenjie/louyihang/caffe/build/tools/convert_imageset /home/chenjie/DataSet/CompCars/data/cropped_image/ ../train_test_split/classification/train_model431_label_start0.txt ../intermediate_data/train_model431_lmdb -resize_width=227 -resize_height=227 -check_size -shuffle true
   ```

   

2. 修改网络最后一层输出类别

3. 调整 solver , LR , 步长, 迭代次数 , 加快最后一层的参数学习速率

4. 加载 pre-training 模型, 启动训练

   

### selective search算法

[算法介绍]: https://blog.csdn.net/lianhuijuan/article/details/64443008?locationNum=1&amp;amp;amp;amp;amp;amp;amp;fps=1
[算法介绍]: https://blog.csdn.net/guoyunfei20/article/details/78723646





rbg 大神博客  http://www.rossgirshick.info/#girshick2014rcnn

r-cnn 算法详解 https://blog.csdn.net/shenxiaolu1984/article/details/51066975 

1. 如何得到候选框

   1. 候选框的生成规则, 合并规则

2. 如何回归位置

   

fast rcnn 论文, 

博客 https://blog.csdn.net/shenxiaolu1984/article/details/51036677

https://blog.csdn.net/yzf0011/article/details/76758337

Roi 与feature map 尺度如何对应, 

fast rcnn 是一种 end-to-end with a multi-task loss

https://blog.csdn.net/Wonder233/article/details/53671018

论文详解: https://blog.csdn.net/WoPawn/article/details/52463853?locationNum=5

github : https://github.com/rbgirshick/fast-rcnn



code 解析: https://blog.csdn.net/lixiang2012521/article/details/77010563

code train 阶段 代码 https://blog.csdn.net/linj_m/article/details/48930179

code  caffe 解析 https://blog.csdn.net/u013010889/article/details/78574879   感觉不错

1. 为什么fast rcnn 速度比rcnn 快很多
   	2. fast 对 rcnn的改进点

建议框

​	selective search算法提取约2k个建议框



1. 网络结构
    2. 新的层 以及作用
      3. 全连接层提速
      4. 候选框的产生和选择 
      5. 特征提取
      6. 分类器的使用
      7. 位置的回归

         

问题: 

1. 如何确定调整某个参数 最终会使我的模型达到我要的效果, ?
2. 这个参数如何调整, 单一变量调整还是 多变量调整. ?
3. 变量之间对模型的影响?



## 论文 Fast R-CNN

a Fast Region-based Convolutional Network 
deep ConvNets 提高 object detection accuracy ,  

Complexity arises because detection requires the accurate localization of objects
有两个挑战: 

1. 众多的 object locations (called "proposals") 需要处理

2. these candidates provide only rough localization that must be refined to achieve precise localization

   这些问题需要考虑 速度, 准确度, 

   简化训练过程, 提供了一种 `single-stage training algorithm, `jointly learns to classify object proposals and refine their spatial locations.



Rcnn 的问题, 他做forward 对每一个 object proposal , 没有 sharing computation, 

![1530796028579](/home/xjx/Documents/论文/论文中图片/1530796028579.png)

two sibling output 

#### 2. Fast R-CNN architecture and training

input an entire image and a set of object proposals



multi-task
training improves pure classification accuracy relative to
training for classification alone.



### opencv Video image 读取



# 7-6

问题1 : 预选框的选择, 

- ss 出 2k个proposals 
- 

## SPP

spatial pyramid pooling 

![](/home/xjx/Documents/论文/论文中图片/20170716201558581.png)

spp 与 roi pooling 区别 联系, 

![1530858315965](/tmp/1530858315965.png)

## fast rcnn data 层

python 层如何调用, 如何创建, 如何使用, 

写层需要哪些要求

caffe python层创建网站

[]: https://chrischoy.github.io/research/caffe-python-layer/



```python
class RoIDataLayer(caffe.Layer):
    
class BlobFetcher(Process):
   
```

![](/home/xjx/Documents/论文/论文中图片/20161012105932773.jpeg)

![](/home/xjx/Documents/论文/论文中图片/20161012110621831.jpeg)



## faster R-CNN

Region Proposal Network (RPN) 

shares full-image convolutional features with the detection network

- An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position
- We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features

- “attention” mechanisms, the RPN component tells the unified network where to look



# 总结

```
a  :recls_K-X_convf_dropout_rpnalikeposebeforenmsbatch4_negratio3_iou0_5
b  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio2_iou0.75
c  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3
d  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.6
e  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.75
f  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.80
g  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_iou0.85
h  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_ne_po_ratio10
i  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_ne_po_ratio25
j  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5
k  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio3_posiou0.5nmsconf0.5
l  :recls_K-X_convf_rpnalikeposebeforenmsbatch4_negratio4_iou0.75
m  :recls_K-X_featuremap2_rpnalikeposebeforenmsbatch4_negratio3_iou0.5
n  :recls_K-X_featuremap3_rpnalikeposebeforenmsbatch4_negratio3_iou0.5
```
ss

|      |      |      |      |      |      |      |      |      |      |      |      |      |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|      |      |      |      |      |      |      |      |      |      |      |      |      |



|               | a    | b    | c    | d    | e    | f    | g    | h    | i    | j    | k    | l    | m   | n   |
| ------------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|  d1260.5.jpg    | drop n3,p5 | n2,p75 | n3p7 | n3,p6 | n3,p75 | n3,p8 | n3,p85 | n3,r10 |n3,r25|n3,p5|n3,p5,ms5|n4,p75|f2,n3,p5|f3,n3,p5|
|  |      |      |||||||||||||
|  d1260_crp.jpg    | 0.8 | 0.7 | .71 | .82 | .68 | .69 | .66 | .89 |||89|70|47|33|
| 人与人之间的误检  大框 |      |      |||||||||||||
|  d1373.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  d1374.jpg    | 0.02人与人误检, 0.9 坐着的人 | 0. | 0. | .03  . | 0 | 0 | 0 | .12 |14|14|14|0|69|3|
|      |      |      |||||||||||||
|  d1411.jpg    | 0.01 人与人误检 | 0 | 0.01 |      | 0 | 0 | 0 | .03 |4|3|3|0|25|3|
|      |      |      |||||||||||||
|  d1493.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  d1510.jpg    | 0.88 坐着的人 |  |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  d1530.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  d1651.jpg    | 0.07大人与人的误检 | 0.03 | .06 | .11 | .05 | .05 | .04 | .22 |26|26|23|5|30|57|
|      |      |      |||||||||||||
|  d1652.jpg    | 0.63 大人与人的误检 | 0.72 | .72 | .85 | .7 | .72 | .69 | .88 ||||72||9|
|      |      |      |||||||||||||
|  d1653.jpg    | 0.57大人与人的误检 | 0.66 | .61 | .79 | .6 | .55 | .53 | .88 |89|89|90|59|90|10|
|      |      |      |||||||||||||
|  d1654.jpg    | 0.31大人与人的误检 | .14 | .13 | .33 | .12 | .10 | .11 | .54 |59|60|60|11||10|
|      |      |      |||||||||||||
|  d1657.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  d1660.jpg    | 0.22大人与人的误检 | .10 | .06 | .22 | .07 | .06 | .07 | 59 |61|62|59|7|||
|      |      |      |||||||||||||
|  d1662.jpg    | 0.31大人与人的误检 | .16 | .15 | .32 | .13 | .13 | .13 | 58 |63|65|61|14|||
|      |      |      |||||||||||||
|  d1793.jpg    | 0.31大人与人的误检 | .24 | .17 | .46 | .16 | .14 | .17 | 70 |72|71|73|16|90|27|
|      |      |      |||||||||||||
|  d1794.jpg    | 0.80 小人与人误检 | 无 |      | 0 | 0 |      |      |      |||||||
|      |      | 坐小人.86 |.83|.74|0.8|.85|.84|69|70|66|67|86|58||
|  e1095.jpg    | 0.75 坐着的人 | .85 | .82 | .76 | .76 | .81 | 82 | 73 |77|73|72|86|57||
|      |      |      |||||||||||||
|  e1096.jpg    | 0.17 小人与人的误检 | .03 | .03 | .06 | .03 | .03 | 3 | 10 |11|10|12|3|73|64|
|      |      |      |||||||||||||
|      |  |  |  |  |  |  |  |  ||||13|45|62|
|      |      |      |||||||||||||
|  e1098.jpg    | 0.22小人与人的误检 | .06 | .07 | .14 | .07 | .07 | 6 | 21 |21|21|23|7|54|76|
|      |      |      |||||||||||||
|  e1099.jpg    | 0.24 小人与人的误检 | .07 | .06 | .12 | .06 | .06 | 6 | 19 |19|16|20|6|47|78|
|      |      |      |||||||||||||
|  e1100.jpg    | 0.36 小人与人的误检 | .06 | .07 | .12 | .06 | .07 | 6 | 21 |21|16|24|7|44|78|
|      |      |      |||||||||||||
|  e1139.jpg    | 0.25 小人与人的误检 | .04 | .03 | .07 | .03 | .04 | 4 | 14 |14|13|15|4|72|68|
|      |      |      |||||||||||||
|  e1140.jpg    | 0.29小人与人的误检 | .02 | 0.02 | .06 | .02 | .02 | 2 | 21 |23|20|22|2|84|86|
|      |      |      |||||||||||||
|  e1145.jpg    | 0.36 小人与人的误检 | .07 | .06 | .21 | .06 | .07 | 6 | 42 |42|39|44|7|87|87|
|      |      |      |||||||||||||
|  e1146.jpg    | 0.50小人与人的误检 | .03 | .03 | .06 | .03 | .03 | 3 | 12 |13|12|14|3|70|87|
|      |      |      ||||||||||||84|
|  e1375.jpg    |      |      |      |      |      |      |      |      ||||||镜子 90  81|
|      |      |      |||||||||||||
|  e243.jpg    | 0.1小人与人误检 | .01 | .01 | .02 | .01 | .01 | .01 | 6 |6|7|9|1|33|63|
|      |      |      ||||||||||||其他人 82-86|
|  e244.jpg    | 0.71小人与人的误检 | .56 | .53 | .72 | .54 | .57 | 56 | 76 |77|76|76|59|83|89|
|      | 0.63 镜子里的人 | 1 |1|1||||||||||镜子 60|
|  e256.jpg    | 0.73小人与人的误检 | .51 | .51 | .69 | .52 | .54 | 54 | 75 |76|74|76|57|76|87|
|      | 0.65 镜子里的人 | 1 |1|1||||||||||58|
|  e258.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      ||||||||||||镜子 57|
|  e259.jpg    | 0.3小人与人的误检 | .05 | .04 | .1 | .03 | .03 | 4 | 20 |20|19|19|4|77|85|
|      |      |      ||||||||||||镜子 56|
|  e281.jpg    | 0.2小人与人的误检 | .04 | .03 | .07 | .03 | .03 | 3 | 13 |13|14|13|3|79|87|
|      |      |      ||||||||||||62|
|  e689.jpg    | 0.33小人与人的误检 | .1 | .11 | .2 | .1 | .09 | 11 | 39 |36|37|36|9|67|85|
|      |      |      ||||||||||||57|
|  e698.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  f208.jpg    | 0.84小人与人之间 | .4 | .39 | .65 | .41 | .39 | 41 | 74 |75|73|77|43|||
|      |      |      |||||||||||||
|  f23.jpg    | 0.11左小人,右小人0.79, | .14       .66 | .09          .64 | .24       .88 | .12      .64 | .1     .64 | 11    61 | 48  91 |48  91|46   92|45  91|12  65|91   99|14   97|
|  |  |  |  |  |  |  | | |||||89 中间做的人|33|
|      | 中间坐小人0.89 |      |||||||||||||
|  f5574.jpg    | 0.22,0.86 左小人, 右小人0.66 | .2  ,75   .7 | .17 .74  .66 | .03 .76         .71 | .19 .72  .69 | .15 .70  .66 | 17   72  66 | 51  87   74 |47  86  75|50  84  75|44  81  75|16 76  66||26  82     70|
|      | 中间中人 0.70 | .93 ||.88||||84|87|86|85|96|||
|  f5610.jpg    | 0.19中间误检大人 | .04 | .05 | .11 | .04 | .04 | 4 | 24 |26|24|26|4|77|70|
|      |      |      |||||||||||||
|  f5944.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  f5948.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  f5949.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  f5954.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  f5959.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  f5962.jpg    | 0.07中间误检大人 | .02 | .03 | .05 | .02 | .02 | 2 | 5 |9|10|10|3|52|86|
|      |      |      |||||||||||||
|  f5966.jpg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  timg (1).jpeg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  timg (2).jpeg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|  timg (3).jpeg    | 0.89左 | .97 | .95 |      |      |      |      |      |||||||
|      | 0.69 右 | .85 |.83|.88|.84|.86|83|86|86|85|89|87|||
|  timg.jpeg    |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|      |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|      |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|      |      |      |      |      |      |      |      |      |||||||
|      |      |      |||||||||||||
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
|               |      |      |      |      |      |      |      |      |      |      |      |      |      |      |

